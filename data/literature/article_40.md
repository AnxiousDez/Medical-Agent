# Reporting guideline for Chatbot Health Advice studies: the CHART statement.

<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med</journal-id><journal-id journal-id-type="iso-abbrev">BMC Med</journal-id><journal-title-group><journal-title>BMC Medicine</journal-title></journal-title-group><issn pub-type="epub">1741-7015</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">12315282</article-id><article-id pub-id-type="pmid">40745595</article-id>
<article-id pub-id-type="publisher-id">4274</article-id><article-id pub-id-type="doi">10.1186/s12916-025-04274-w</article-id><article-categories><subj-group subj-group-type="heading"><subject>Guideline</subject></subj-group></article-categories><title-group><article-title>Reporting guideline for Chatbot Health Advice studies: the CHART statement</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Huo</surname><given-names>Bright</given-names></name><address><email>brighthuo@dal.ca</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Collins</surname><given-names>Gary</given-names></name><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Chartash</surname><given-names>David</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Thirunavukarasu</surname><given-names>Arun</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Flanagin</surname><given-names>Annette</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Iorio</surname><given-names>Alfonso</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Cacciamani</surname><given-names>Giovanni</given-names></name><xref ref-type="aff" rid="Aff8">8</xref><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Xi</given-names></name><xref ref-type="aff" rid="Aff10">10</xref><xref ref-type="aff" rid="Aff11">11</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Nan</given-names></name><xref ref-type="aff" rid="Aff12">12</xref></contrib><contrib contrib-type="author"><name><surname>Mathur</surname><given-names>Piyush</given-names></name><xref ref-type="aff" rid="Aff13">13</xref></contrib><contrib contrib-type="author"><name><surname>Chan</surname><given-names>An-Wen</given-names></name><xref ref-type="aff" rid="Aff14">14</xref></contrib><contrib contrib-type="author"><name><surname>Laine</surname><given-names>Christine</given-names></name><xref ref-type="aff" rid="Aff15">15</xref><xref ref-type="aff" rid="Aff16">16</xref></contrib><contrib contrib-type="author"><name><surname>Pacella</surname><given-names>Daniela</given-names></name><xref ref-type="aff" rid="Aff17">17</xref></contrib><contrib contrib-type="author"><name><surname>Berkwits</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff18">18</xref></contrib><contrib contrib-type="author"><name><surname>Antoniou</surname><given-names>Stavros A.</given-names></name><xref ref-type="aff" rid="Aff19">19</xref></contrib><contrib contrib-type="author"><name><surname>Camaradou</surname><given-names>Jennifer C.</given-names></name><xref ref-type="aff" rid="Aff20">20</xref></contrib><contrib contrib-type="author"><name><surname>Canfield</surname><given-names>Carolyn</given-names></name><xref ref-type="aff" rid="Aff21">21</xref></contrib><contrib contrib-type="author"><name><surname>Mittelman</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff22">22</xref></contrib><contrib contrib-type="author"><name><surname>Feeney</surname><given-names>Timothy</given-names></name><xref ref-type="aff" rid="Aff23">23</xref><xref ref-type="aff" rid="Aff24">24</xref></contrib><contrib contrib-type="author"><name><surname>Loder</surname><given-names>Elizabeth</given-names></name><xref ref-type="aff" rid="Aff23">23</xref><xref ref-type="aff" rid="Aff25">25</xref></contrib><contrib contrib-type="author"><name><surname>Agha</surname><given-names>Riaz</given-names></name><xref ref-type="aff" rid="Aff26">26</xref><xref ref-type="aff" rid="Aff27">27</xref></contrib><contrib contrib-type="author"><name><surname>Saha</surname><given-names>Ashirbani</given-names></name><xref ref-type="aff" rid="Aff28">28</xref></contrib><contrib contrib-type="author"><name><surname>Mayol</surname><given-names>Julio</given-names></name><xref ref-type="aff" rid="Aff29">29</xref></contrib><contrib contrib-type="author"><name><surname>Sunjaya</surname><given-names>Anthony</given-names></name><xref ref-type="aff" rid="Aff30">30</xref></contrib><contrib contrib-type="author"><name><surname>Harvey</surname><given-names>Hugh</given-names></name><xref ref-type="aff" rid="Aff31">31</xref></contrib><contrib contrib-type="author"><name><surname>Ng</surname><given-names>Jeremy Y.</given-names></name><xref ref-type="aff" rid="Aff32">32</xref></contrib><contrib contrib-type="author"><name><surname>McKechnie</surname><given-names>Tyler</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Yung</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff33">33</xref></contrib><contrib contrib-type="author"><name><surname>Verma</surname><given-names>Nipun</given-names></name><xref ref-type="aff" rid="Aff34">34</xref></contrib><contrib contrib-type="author"><name><surname>Stiglic</surname><given-names>Gregor</given-names></name><xref ref-type="aff" rid="Aff35">35</xref></contrib><contrib contrib-type="author"><name><surname>McCradden</surname><given-names>Melissa</given-names></name><xref ref-type="aff" rid="Aff36">36</xref></contrib><contrib contrib-type="author"><name><surname>Ramji</surname><given-names>Karim</given-names></name><xref ref-type="aff" rid="Aff37">37</xref></contrib><contrib contrib-type="author"><name><surname>Boudreau</surname><given-names>Vanessa</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ortenzi</surname><given-names>Monica</given-names></name><xref ref-type="aff" rid="Aff38">38</xref></contrib><contrib contrib-type="author"><name><surname>Meerpohl</surname><given-names>Joerg</given-names></name><xref ref-type="aff" rid="Aff39">39</xref><xref ref-type="aff" rid="Aff40">40</xref></contrib><contrib contrib-type="author"><name><surname>Vandvik</surname><given-names>Per Olav</given-names></name><xref ref-type="aff" rid="Aff40">40</xref><xref ref-type="aff" rid="Aff41">41</xref></contrib><contrib contrib-type="author"><name><surname>Agoritsas</surname><given-names>Thomas</given-names></name><xref ref-type="aff" rid="Aff7">7</xref><xref ref-type="aff" rid="Aff41">41</xref><xref ref-type="aff" rid="Aff42">42</xref></contrib><contrib contrib-type="author"><name><surname>Samuel</surname><given-names>Diana</given-names></name><xref ref-type="aff" rid="Aff43">43</xref></contrib><contrib contrib-type="author"><name><surname>Frankish</surname><given-names>Helen</given-names></name><xref ref-type="aff" rid="Aff44">44</xref></contrib><contrib contrib-type="author"><name><surname>Anderson</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff45">45</xref><xref ref-type="aff" rid="Aff46">46</xref></contrib><contrib contrib-type="author"><name><surname>Yao</surname><given-names>Xiaomei</given-names></name><xref ref-type="aff" rid="Aff28">28</xref></contrib><contrib contrib-type="author"><name><surname>Loeb</surname><given-names>Stacy</given-names></name><xref ref-type="aff" rid="Aff47">47</xref></contrib><contrib contrib-type="author"><name><surname>Lokker</surname><given-names>Cynthia</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xiaoxuan</given-names></name><xref ref-type="aff" rid="Aff48">48</xref></contrib><contrib contrib-type="author"><name><surname>Guallar</surname><given-names>Eliseo</given-names></name><xref ref-type="aff" rid="Aff49">49</xref></contrib><contrib contrib-type="author"><name><surname>Guyatt</surname><given-names>Gordon</given-names></name><xref ref-type="aff" rid="Aff7">7</xref><xref ref-type="aff" rid="Aff41">41</xref></contrib><contrib contrib-type="author"><collab>The CHART Collaborative</collab></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02fa3aq29</institution-id><institution-id institution-id-type="GRID">grid.25073.33</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8227</institution-id><institution>Division of General Surgery, Department of Surgery, </institution><institution>McMaster University, </institution></institution-wrap>Hamilton, Canada </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/052gg0110</institution-id><institution-id institution-id-type="GRID">grid.4991.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8948</institution-id><institution>UK EQUATOR Centre, </institution><institution>University of Oxford, </institution></institution-wrap>Oxford, UK </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/052gg0110</institution-id><institution-id institution-id-type="GRID">grid.4991.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8948</institution-id><institution>Centre for Statistics in Medicine, Nuffield Department of Orthopaedics, Rheumatology &#x00026; 401 Musculoskeletal Sciences, Botnar Research Centre,, </institution><institution>University of Oxford, </institution></institution-wrap>Oxford, UK </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03v76x132</institution-id><institution-id institution-id-type="GRID">grid.47100.32</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8710</institution-id><institution>Department of Biomedical Informatics and Data Science, </institution><institution>Yale University School of Medicine, </institution></institution-wrap>New Haven, USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/052gg0110</institution-id><institution-id institution-id-type="GRID">grid.4991.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8948</institution-id><institution>Nuffield Department of Clinical Neurosciences, Medical Sciences Division, </institution><institution>University of Oxford, </institution></institution-wrap>Oxford, UK </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03p6gt485</institution-id><institution-id institution-id-type="GRID">grid.413701.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 4647 675X</institution-id><institution>JAMA and JAMA Network, American Medical Association, </institution></institution-wrap>Chicago, USA </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02fa3aq29</institution-id><institution-id institution-id-type="GRID">grid.25073.33</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8227</institution-id><institution>Department of Health Research Methods, Evidence, and Impact; Department of Medicine, </institution><institution>McMaster University, </institution></institution-wrap>Hamilton, Canada </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03taz7m60</institution-id><institution-id institution-id-type="GRID">grid.42505.36</institution-id><institution-id institution-id-type="ISNI">0000 0001 2156 6853</institution-id><institution>USC Institute of Urology and Catherine and Joseph Aresty Department of Urology, Keck School of Medicine, </institution><institution>University of Southern California, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03taz7m60</institution-id><institution-id institution-id-type="GRID">grid.42505.36</institution-id><institution-id institution-id-type="ISNI">0000 0001 2156 6853</institution-id><institution>Artificial Intelligence Center at USC Urology, </institution><institution>USC Institute of Urology, University of Southern California, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/007mrxy13</institution-id><institution-id institution-id-type="GRID">grid.412901.f</institution-id><institution-id institution-id-type="ISNI">0000 0004 1770 1022</institution-id><institution>Sports Medicine Center, </institution><institution>West China Hospital, Sichuan University, </institution></institution-wrap>Chengdu, China </aff><aff id="Aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/007mrxy13</institution-id><institution-id institution-id-type="GRID">grid.412901.f</institution-id><institution-id institution-id-type="ISNI">0000 0004 1770 1022</institution-id><institution>Department of Orthopedics and Orthopedic Research Institute, </institution><institution>West China Hospital, Sichuan University, </institution></institution-wrap>Chengdu, China </aff><aff id="Aff12"><label>12</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01tgyzw49</institution-id><institution-id institution-id-type="GRID">grid.4280.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2180 6431</institution-id><institution>Duke-NUS Medical School, </institution><institution>National University of Singapore, </institution></institution-wrap>Singapore, Singapore </aff><aff id="Aff13"><label>13</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/051fd9666</institution-id><institution-id institution-id-type="GRID">grid.67105.35</institution-id><institution-id institution-id-type="ISNI">0000 0001 2164 3847</institution-id><institution>Cleveland Clinic, </institution><institution>Case Western Reserve University, </institution></institution-wrap>Cleveland, USA </aff><aff id="Aff14"><label>14</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Department of Medicine, </institution><institution>Women&#x02019;s College Research Institute, University of Toronto, </institution></institution-wrap>Toronto, Canada </aff><aff id="Aff15"><label>15</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03671qm90</institution-id><institution-id institution-id-type="GRID">grid.417947.8</institution-id><institution-id institution-id-type="ISNI">0000 0000 8606 7660</institution-id><institution>Annals of Internal Medicine, </institution><institution>American College of Physicians, </institution></institution-wrap>Philadelphia, USA </aff><aff id="Aff16"><label>16</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03671qm90</institution-id><institution-id institution-id-type="GRID">grid.417947.8</institution-id><institution-id institution-id-type="ISNI">0000 0000 8606 7660</institution-id><institution>American College of Physicians, </institution></institution-wrap>Philadelphia, USA </aff><aff id="Aff17"><label>17</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05290cv24</institution-id><institution-id institution-id-type="GRID">grid.4691.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 0790 385X</institution-id><institution>Department of Public Health, </institution><institution>University of Naples Federico II, </institution></institution-wrap>Naples, Italy </aff><aff id="Aff18"><label>18</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042twtr12</institution-id><institution-id institution-id-type="GRID">grid.416738.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2163 0069</institution-id><institution>Director, Office of Science Dissemination, Office of Science, Centers for Disease Control and Prevention, </institution></institution-wrap>Atlanta, GA USA </aff><aff id="Aff19"><label>19</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01663qy58</institution-id><institution-id institution-id-type="GRID">grid.417144.3</institution-id><institution>Department of General Surgery, </institution><institution>Papageorgiou General Hospital, </institution></institution-wrap>Thessaloniki, Greece </aff><aff id="Aff20"><label>20</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/008n7pv89</institution-id><institution-id institution-id-type="GRID">grid.11201.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2219 0747</institution-id><institution>British Psychological Society, </institution><institution>University of Plymouth, </institution></institution-wrap>Plymouth, UK </aff><aff id="Aff21"><label>21</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03rmrcq20</institution-id><institution-id institution-id-type="GRID">grid.17091.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2288 9830</institution-id><institution>Innovation Support Unit, Department of Family Practice, </institution><institution>University of British Columbia, </institution></institution-wrap>Vancouver, Canada </aff><aff id="Aff22"><label>22</label>Patient SME, Independent Cybersecurity Professional, London, UK </aff><aff id="Aff23"><label>23</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02caz1f24</institution-id><institution-id institution-id-type="GRID">grid.431398.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8489</institution-id><institution>The BMJ, </institution></institution-wrap>London, UK </aff><aff id="Aff24"><label>24</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0130frc33</institution-id><institution-id institution-id-type="GRID">grid.10698.36</institution-id><institution-id institution-id-type="ISNI">0000 0001 2248 3208</institution-id><institution>Department of Epidemiology, Gillings School of Global Public Health, </institution><institution>University of North Carolina at Chapel Hill, </institution></institution-wrap>Chapel Hill, NC USA </aff><aff id="Aff25"><label>25</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04b6nzv94</institution-id><institution-id institution-id-type="GRID">grid.62560.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8294</institution-id><institution>Department of Neurology, </institution><institution>Brigham and Women&#x02019;s Hospital, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff26"><label>26</label>International Journal of Surgery, London, UK </aff><aff id="Aff27"><label>27</label>Eworkflow Ltd, London, UK </aff><aff id="Aff28"><label>28</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02fa3aq29</institution-id><institution-id institution-id-type="GRID">grid.25073.33</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8227</institution-id><institution>Department of Oncology, </institution><institution>McMaster University, </institution></institution-wrap>Hamilton, Canada </aff><aff id="Aff29"><label>29</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04d0ybj29</institution-id><institution-id institution-id-type="GRID">grid.411068.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 0671 5785</institution-id><institution>Hospital Clinico San Carlos, </institution><institution>Instituto de Investigaci&#x000f3;n Sanitaria San Carlos, Facultad de Medicina Universidad Complutense de Madrid, </institution></institution-wrap>Madrid, Spain </aff><aff id="Aff30"><label>30</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/023331s46</institution-id><institution-id institution-id-type="GRID">grid.415508.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 1964 6010</institution-id><institution>The George Institute for Global Health; Tyree Institute of Health Engineering, UNSW Engineering; School of Population Health, UNSW Medicine and Health, </institution></institution-wrap>Sydney, Australia </aff><aff id="Aff31"><label>31</label>Hardian Health, London, UK </aff><aff id="Aff32"><label>32</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05jtef216</institution-id><institution-id institution-id-type="ISNI">0000 0004 0500 0659</institution-id><institution>Centre for Journalology, </institution><institution>Ottawa Hospital Research Institute, </institution></institution-wrap>Ottawa, Canada </aff><aff id="Aff33"><label>33</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03xjacd83</institution-id><institution-id institution-id-type="GRID">grid.239578.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 0675 4725</institution-id><institution>Digestive Diseases Institute, Cleveland Clinic, </institution></institution-wrap>Cleveland, OH USA </aff><aff id="Aff34"><label>34</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/009nfym65</institution-id><institution-id institution-id-type="GRID">grid.415131.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1767 2903</institution-id><institution>Postgraduate Institute of Medical Education and Research, </institution></institution-wrap>Chandigarh, India </aff><aff id="Aff35"><label>35</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01d5jce07</institution-id><institution-id institution-id-type="GRID">grid.8647.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 0637 0731</institution-id><institution>University of Maribor, </institution></institution-wrap>Maribor, Slovenia </aff><aff id="Aff36"><label>36</label>Australian Institute for Machine Learning (AIML), Adelaide, Australia </aff><aff id="Aff37"><label>37</label>Phelix AI, Toronto, Canada </aff><aff id="Aff38"><label>38</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00x69rs40</institution-id><institution-id institution-id-type="GRID">grid.7010.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 1017 3210</institution-id><institution>Universit&#x000e0; Politecnica delle Marche, Clinica di Chirurgia Generale e d&#x02019;Urgenza, </institution></institution-wrap>Ancona, Italy </aff><aff id="Aff39"><label>39</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0245cg223</institution-id><institution-id institution-id-type="GRID">grid.5963.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 0491 7203</institution-id><institution>Institute for Evidence in Medicine, Medical Center &#x00026; Faculty of Medicine, </institution><institution>University of Freiburg, </institution></institution-wrap>Freiburg im Breisgau, Germany </aff><aff id="Aff40"><label>40</label>Cochrane Germany, Cochrane Germany Foundation, Freiburg, Germany </aff><aff id="Aff41"><label>41</label>MAGIC Evidence Ecosystem Foundation, Oslo, Norway </aff><aff id="Aff42"><label>42</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01m1pv723</institution-id><institution-id institution-id-type="GRID">grid.150338.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0721 9812</institution-id><institution>University Hospitals of Geneva, </institution></institution-wrap>Geneva, Switzerland </aff><aff id="Aff43"><label>43</label>The Lancet Digital Health, London, UK </aff><aff id="Aff44"><label>44</label>The Lancet, London, UK </aff><aff id="Aff45"><label>45</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/027m9bs27</institution-id><institution-id institution-id-type="GRID">grid.5379.8</institution-id><institution-id institution-id-type="ISNI">0000 0001 2166 2407</institution-id><institution>NIHR Clinical Lecturer, Health Organisation, Policy, Economics (HOPE), Centre for Primary Care &#x00026; Health Services Research, </institution><institution>The University of Manchester, </institution></institution-wrap>Manchester, UK </aff><aff id="Aff46"><label>46</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0090zs177</institution-id><institution-id institution-id-type="GRID">grid.13063.37</institution-id><institution-id institution-id-type="ISNI">0000 0001 0789 5319</institution-id><institution>Senior Visiting Fellow, LSE Health, London School of Economics and Political Science, </institution></institution-wrap>Manchester, UK </aff><aff id="Aff47"><label>47</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0190ak572</institution-id><institution-id institution-id-type="GRID">grid.137628.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8753</institution-id><institution>New York University Langone Health, </institution></institution-wrap>New York City, USA </aff><aff id="Aff48"><label>48</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03angcq70</institution-id><institution-id institution-id-type="GRID">grid.6572.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7486</institution-id><institution>College of Medicine and Health, </institution><institution>University of Birmingham, </institution></institution-wrap>Birmingham, UK </aff><aff id="Aff49"><label>49</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0190ak572</institution-id><institution-id institution-id-type="GRID">grid.137628.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8753</institution-id><institution>School of Global Public Health, </institution><institution>New York University, </institution></institution-wrap>New York City, USA </aff></contrib-group><pub-date pub-type="epub"><day>1</day><month>8</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>1</day><month>8</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>23</volume><elocation-id>447</elocation-id><history><date date-type="received"><day>11</day><month>6</month><year>2025</year></date><date date-type="accepted"><day>10</day><month>7</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">The Chatbot Assessment Reporting Tool (CHART) is a reporting guideline developed to provide reporting recommendations for studies evaluating the performance of generative artificial intelligence (AI)-driven chatbots when summarizing clinical evidence and providing health advice, referred to as Chatbot Health Advice (CHA) studies.</p></sec><sec><title>Methods</title><p id="Par2">CHART was developed in several phases after performing a comprehensive systematic review to identify variation in the conduct, reporting, and methodology in CHA studies. Findings from the review were used to develop a draft checklist that was revised through an international, multidisciplinary modified asynchronous Delphi consensus process of 531 stakeholders, three synchronous panel consensus meetings of 48 stakeholders, and subsequent pilot testing of the checklist.</p></sec><sec><title>Results</title><p id="Par3">CHART includes 12 items and 39 subitems to promote transparent and comprehensive reporting of CHA studies. These include Title (subitem 1a), Abstract/Summary (subitem 1b), Background (subitems 2ab), Model Identifiers (subitems 3ab), Model Details (subitems 4abc), Prompt Engineering (subitems 5ab), Query Strategy (subitems 6abcd), Performance Evaluation (subitems 7ab), Sample Size (subitem 8), Data Analysis (subitem 9a), Results (subitems 10abc), Discussion (subitems 11abc), Disclosures (subitem 12a), Funding (subitem 12b), Ethics (subitem 12c), Protocol (subitem 12d), and Data Availability (subitem 12e).</p></sec><sec><title>Conclusion</title><p id="Par4">The CHART checklist and corresponding methodological diagram were designed to support key stakeholders including clinicians, researchers, editors, peer reviewers, and readers in reporting, understanding, and interpreting the findings of CHA studies.</p></sec><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1186/s12916-025-04274-w.</p></sec></abstract><abstract id="Abs2" abstract-type="highlights"><title>Key messages</title><p id="Par5">
<list list-type="bullet"><list-item><p id="Par6">CHART was developed by performing a systematic review, Delphi consensus of 531 international stakeholders, and several consensus meetings among an expert panel comprised 48 members.</p></list-item><list-item><p id="Par7">The CHART statement outlines 12 key reporting items for Chatbot Health Advice studies in the form of a checklist and methodology diagram.</p></list-item><list-item><p id="Par8">All stakeholders including clinicians, researchers, and journal editors should encourage the transparent reporting of Chatbot Health Advice studies.</p></list-item></list></p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1186/s12916-025-04274-w.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>LLMs</kwd><kwd>Generative AI</kwd><kwd>Reporting standards</kwd></kwd-group><funding-group><award-group><funding-source><institution>PGME, McMaster University</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; BioMed Central Ltd., part of Springer Nature 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p id="Par9">Artificial intelligence (AI) has made great strides toward clinical applications in healthcare, with deep learning algorithms performing comparably to current gold standards in several areas in patient care [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. With the introduction of large language models (LLMs) into mainstream use, there has been an explosive rise in the number of studies evaluating the performance of generative artificial intelligence (AI)-driven chatbots in summarizing evidence and providing health advice [<xref ref-type="bibr" rid="CR3">3</xref>], termed Chatbot Health Advice (CHA) studies. Investigators typically develop prompts to query generative AI models through a chat-based interface for the purpose of summarizing clinical evidence or obtaining health advice including but not limited to health promotion, prevention, screening, diagnosis, treatment, and/or general health information. For example, physicians may query generative AI-driven chatbots to identify whether their patient should receive colorectal cancer screening [<xref ref-type="bibr" rid="CR4">4</xref>]. Similarly, a patient may ask questions about their upcoming surgery for gastroesophageal reflux disease [<xref ref-type="bibr" rid="CR5">5</xref>]. The intense interest in using generative AI-driven chatbots for health advice has generated numerous CHA studies in a short timeframe [<xref ref-type="bibr" rid="CR6">6</xref>]. Investigators may include clinicians, scientists, or patients, bringing different technical expertise and personal perspectives to study methodology including prompt engineering and model response evaluation.</p><p id="Par10">These studies represent a growing genre of medical AI research [<xref ref-type="bibr" rid="CR7">7</xref>]. At least 137 CHA studies were published less than a year after the release of ChatGPT in November 2022, but the completeness of reporting among these studies has been highly variable [<xref ref-type="bibr" rid="CR6">6</xref>]. For instance, few articles elaborate on the development of their prompts, while fewer than 40% of articles report key elements of their query strategy including the date of their search, the number of chat sessions used, or the number of prompts [<xref ref-type="bibr" rid="CR6">6</xref>]. Raw prompts and model output are infrequently reported, and most articles present an insufficient amount of information to identify the model and chatbot under evaluation [<xref ref-type="bibr" rid="CR6">6</xref>]. This problem is important because inadequate reporting impairs the ability of readers to interpret the validity and reliability of study findings [<xref ref-type="bibr" rid="CR8">8</xref>]. Flaws in the design, data collection, or conduct of a study may lead to erroneous conclusions or raise the risk of patient harm, particularly if generative AI-driven models are used for health purposes [<xref ref-type="bibr" rid="CR9">9</xref>]. Complete and standardized reporting facilitates critical appraisal and may help identify applications with genuine potential to improve health care, building trust in the use of generative AI models in clinical practice among clinicians, patients, and the general public [<xref ref-type="bibr" rid="CR9">9</xref>].</p><p id="Par11">In response to the growing need for reporting standards for evaluating CHA studies for clinical purposes [<xref ref-type="bibr" rid="CR10">10</xref>], we developed the Chatbot Assessment Reporting Tool (CHART). This reporting standard is an international, multidisciplinary initiative registered with the Enhancing the QUAlity and Transparency Of health Research (EQUATOR) Network [<xref ref-type="bibr" rid="CR11">11</xref>] and was announced in December 2023 [<xref ref-type="bibr" rid="CR3">3</xref>]. This article describes the methodology used to identify, evaluate, and gain consensus on the checklist items and diagram that comprise CHART. We aimed to develop robust guidance to promote high methodological rigor and transparent reporting of CHA studies evaluating the performance of generative AI-driven chatbots when summarizing clinical evidence and providing health advice. The terminology used in this reporting guideline is listed in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Glossary</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Term</th><th align="left">Definition</th></tr></thead><tbody><tr><td align="left">Artificial intelligence (AI)</td><td align="left">The science of developing computer systems that can perform complex tasks approximating human cognitive performance</td></tr><tr><td align="left">Base model</td><td align="left">A pre-existing generative AI model</td></tr><tr><td align="left">Chat session</td><td align="left">An interface in a computing device through which communication takes place between a chatbot and its user through text-based prompts</td></tr><tr><td align="left">Chatbot Health Advice (CHA) study</td><td align="left">Any research study evaluating the performance of chatbots when summarizing health evidence and/or providing clinical advice</td></tr><tr><td align="left">Fine-tuned model</td><td align="left">A base model that has been manipulated through various methods of algorithmic tuning to alter its performance with specificity; methods include but are not limited to reinforcement learning or distillation</td></tr><tr><td align="left">Generative AI-driven chatbot</td><td align="left">A program that permits users to interact with an AI model (such as an LLM) that is designed to respond to user prompts</td></tr><tr><td align="left">Ground truth</td><td align="left">The reference standard, or criteria, on which the model is evaluated to define successful performance</td></tr><tr><td align="left">Large language model (LLM)</td><td align="left">A type of AI model comprising large neural networks trained over large amounts of text usually to produce an output of continuations of text from corresponding prompts known as next word prediction. LLMs are a subset of generative AI models</td></tr><tr><td align="left">Multimodal LLM</td><td align="left">LLMs with the capacity to integrate input from various data types including text speech and/or visual sources</td></tr><tr><td align="left">Natural language processing (NLP)</td><td align="left">A branch of information science that seeks to enable computers to interpret and manipulate human text</td></tr><tr><td align="left">Parameter</td><td align="left">A variable that is tuned iteratively or automatically to optimize the intended outcome of the algorithm. Parameters may be at the model level to optimize tuning (hyperparameters) or &#x0201c;weights&#x0201d; within the model linking layer to layer (parameters)</td></tr><tr><td align="left">Post-implementation/deployment</td><td align="left">Refers to alteration of the generative AI model following its release</td></tr><tr><td align="left">Pre-implementation/deployment</td><td align="left">Refers to alteration of the generative AI model prior to its release</td></tr><tr><td align="left">Prompt</td><td align="left">The input provided by users when interfacing with a generative AI-driven chatbot, leading to input interaction with the AI model</td></tr><tr><td align="left">Prompt engineering</td><td align="left">An iterative testing phase where various pieces of text are inputted into a chatbot to achieve an output informing the development of study prompts</td></tr><tr><td align="left">Query</td><td align="left">The act of communicating with a generative AI-driven chatbot by inputting a prompt into the chatbot which might be a question, comment, or phrase to elicit specific desired outputs from the generative AI model</td></tr><tr><td align="left">Response</td><td align="left">The output of the generative AI-driven chatbot</td></tr><tr><td align="left">Tuned model</td><td align="left">A base model that has been altered to provide focused responses by means other than fine-tuning, including but not limited to retrieval augmented generation, which seeks to alter performance rather than the model</td></tr><tr><td align="left">Zero shot</td><td align="left">A machine learning paradigm in which the task (such as classification) is performed without explicit training, fine-tuning, or other optimization</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec2"><title>Methods</title><p id="Par12">We formed a steering group responsible for overseeing the development of CHART. We developed CHART in alignment with the EQUATOR Network&#x02019;s framework according to the highest methodological standards for reporting guideline development [<xref ref-type="bibr" rid="CR8">8</xref>] and published the protocol in May 2024 [<xref ref-type="bibr" rid="CR7">7</xref>].</p><p id="Par13">To inform the development of CHART, we conducted a comprehensive systematic review to identify information reported in CHA studies. The review protocol was prospectively registered on the Open Sciences Framework: <ext-link ext-link-type="uri" xlink:href="https://osf.io/cxsk3">https://osf.io/cxsk3</ext-link>. The systematic review was devised according to methodological guidance from the Joanna Briggs Institute [<xref ref-type="bibr" rid="CR12">12</xref>]. A systematic literature search was performed with the support of a health sciences librarian using Medline via Ovid, Embase via Elsevier, and Web of Science on October 27th, 2023. Full search syntax from all database searches are provided in the supplementary section of our systematic review [<xref ref-type="bibr" rid="CR6">6</xref>]. We screened 7752 articles to identify 137 eligible articles of interest. Considerable variation in methodology and reporting was observed, and we identified 120 candidate checklist items for CHART (Appendix 1). Full details on this process can be found in our protocol [<xref ref-type="bibr" rid="CR7">7</xref>]. To evaluate these candidate checklist items for inclusion in the CHART checklist, we invited an advisory committee to perform a modified Delphi consensus process and formed an expert panel to conduct synchronous consensus meetings. Full details on this recruitment process can be found in the protocol [<xref ref-type="bibr" rid="CR7">7</xref>]. We considered &#x0201c;experts&#x0201d; as individuals who have made important contributions academically to their discipline, with an emphasis on individuals that have participated in reporting guideline development previously.</p><sec id="Sec3"><title>Modified delphi consensus survey</title><p id="Par14">The steering group invited 1043 members globally to form an advisory committee to participate in a Delphi survey, comprising clinicians, epidemiologists, research methodologists, generative AI researchers, journal editors, chatbot researchers, ethicists, regulatory experts, policy experts, and patient partners. We identified potential committee members using a multi-pronged approach through co-authors published in the top medical journals, public and internal calls through affiliate journals, as well as through snowballing via all members of our expert panel. To identify the top 10 journals across all specialties, we used the journal ranking feature in Scimago. Full details are listed in our protocol [<xref ref-type="bibr" rid="CR6">6</xref>]. Via convenience sampling, we included four editors from the top journals identified. We invited members by email and provided project details as well as our correspondence article and study protocol [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. Members voluntarily registered to participate in our Delphi consensus survey by providing basic demographic information, as well as details of their prior research experience and content expertise. We presented candidate checklist items to the advisory committee using the online Delphi consensus platform Welphi, <italic>Decision Eyes</italic> (<ext-link ext-link-type="uri" xlink:href="http://www.welphi.com">www.welphi.com</ext-link>). Members rated candidate checklist items as one of the following: &#x0201c;include, maybe include, uncertain, maybe exclude, or exclude.&#x0201d; They also suggested additional checklist items. After the first round of voting, advisory committee members engaged in a second round of voting via a modified Delphi consensus survey. Members were able to view the results from the first round and review comments supporting voting considerations. During the second Delphi round, members voted on the same checklist items as well as any additional checklist items from the first round. Advisory committee members were also able to suggest additional checklist items during the second round, generating a total of 28 additional candidate checklist items across both Delphi rounds. A total of 531/1043 (50.9%) members participated in both Delphi consensus rounds, rating a total of 140 candidate checklist items for review by the expert panel (Appendix 1).</p></sec><sec id="Sec4"><title>Expert panel consensus</title><p id="Par15">The steering group assembled an international, multidisciplinary panel comprising a balanced representation of 48 relevant stakeholders including clinicians, statisticians, research methodologists, reporting guideline developers, generative AI researchers, journal editors, chatbot researchers, ethicists, regulatory experts, policy experts, and four patient partners. The distribution of stakeholders among the panel is presented in the supplementary material. The steering group used a prespecified threshold of 80% agreement for inclusion to show majority consensus based on prior work [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. We identified items with at least 80% consensus with the selection of either &#x0201c;include&#x0201d; and &#x0201c;maybe include&#x0201d; together, or &#x0201c;exclude&#x0201d; and &#x0201c;maybe exclude&#x0201d; and posed to the panel whether to include or exclude suggested items. Items not meeting 80% consensus were posed to the panel for further discussion. We also presented raw scores including absolute and relative and frequencies to the expert panel to support their interpretation and decision-making. We held synchronous discussions over three separate panel consensus meetings on Zoom spanning 12 twelve collective hours on June 30th, August 5th, and September 2nd, 2024. Items on which the expert panel disagreed with the advisory committee, as well as items voted as &#x0201c;unsure&#x0201d; by the advisory committee, were discussed among panel members until consensus was reached. Panel members were able to suggest changes to the phrasing of checklist items, as well as suggest additional checklist items. After extensive discussion, the expert panel reached consensus on 12 checklist items (Appendix 2) and 9 abstract checklist items (Appendix 3). A fillable methodological diagram can be found in Appendix 4. A list of panel members can be found in Appendix 5. No items or subitems required voting, as contentious items were discussed thoroughly until consensus was achieved.</p></sec><sec id="Sec5"><title>Pilot testing</title><p id="Par16">Following the panel consensus meetings, draft checklist items were presented to authors of separate, prior CHA studies via an iterative process for pilot testing. Groups of five authors used the draft CHART checklist to evaluate 10 published CHA studies and provide feedback in each round until saturation was reached with respect to no new comments or areas for improvement. Pilot testers were provided with feedback from each round of testing to inform their evaluations. Authors were physicians or CHA study researchers and were not affiliated with the articles under evaluation. We instructed pilot testers to flag any item or subitem that they perceived as unclear, or inappropriate for further assessment by the steering group and re-evaluation by the panel if needed. However, we received positive feedback regarding the length, content, and user experience with the checklist. No items or subitems were flagged as inappropriate. Minor changes were made to the checklist including the phrasing of items, the order of items, and the formatting of the fillable document to optimize user experience with the checklist. No additional items or subitems were suggested. Saturation was reached after two rounds of pilot testing. Full details regarding our methodology can be found in our research protocol [<xref ref-type="bibr" rid="CR7">7</xref>].</p></sec><sec id="Sec6"><title>Deviations from the protocol</title><p id="Par17"> Based on feedback from the expert multidisciplinary panel, we broadened the scope beyond LLMs to include any applications using generative AI due to the dynamically evolving nature of AI research in medicine. Moreover, two expert subgroups were assembled after the panel reviewed the candidate checklist items after the first consensus meeting. First, an expert generative AI subgroup met to evaluate and revise the terminology and checklist items used in this reporting guideline. Second, an expert data analysis subgroup reviewed checklist items related to statistical analysis. The results of both subgroups were presented to the expert panel and were reviewed for approval and discussed at subsequent panel consensus meetings. Finally, due to the complex nature of the conduct and reporting of CHA studies, we developed the checklist items and accompanying diagram for CHART over three separate synchronous, 4-h panel consensus meetings rather than two, as initially planned in our protocol [<xref ref-type="bibr" rid="CR7">7</xref>]. Further guidance and points of emphasis are detailed in the CHART Explanation and Elaboration article [<xref ref-type="bibr" rid="CR14">14</xref>].</p></sec></sec><sec id="Sec7"><title>Results</title><p id="Par18">The CHART methodological diagram can be seen in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The CHART checklist consists of 12 items comprising 39 subitems for the complete and transparent reporting of CHA studies. Items relate to Title &#x00026; Abstract (item 1), Introduction (item 2), Methods (items 3-9), Results (item 10), Discussion (item 11), and Open Science (item 12). Table <xref rid="Tab2" ref-type="table">2</xref> lists the CHART checklist items. Table <xref rid="Tab3" ref-type="table">3</xref> lists the CHART abstract checklist items. <fig id="Fig1"><label>Fig. 1</label><caption><p>The CHART Methodological Diagram</p></caption><graphic xlink:href="12916_2025_4274_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>CHART Checklist</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">HEADING</th><th align="left">
<bold>#</bold>
</th><th align="left">CHART CHECKLIST ITEM</th><th align="left">Page<bold> #*</bold>
</th></tr></thead><tbody><tr><td align="left" colspan="4">Title &#x00026; Abstract</td></tr><tr><td align="left">&#x02003;Title</td><td align="left">1a</td><td align="left">State that the study is assessing one or more generative AI-driven chatbots for clinical evidence or health advice.</td><td align="left"/></tr><tr><td align="left">&#x02003;Abstract/Summary</td><td align="left">1b</td><td align="left">Apply a structured format, if applicable.</td><td align="left"/></tr><tr><td align="left" colspan="4">Introduction</td></tr><tr><td align="left" rowspan="2">&#x02003;Background</td><td align="left">2a</td><td align="left">State the scientific background, rationale, and healthcare context for evaluating the generative AI-driven chatbot(s), referencing relevant literature when applicable.</td><td align="left"/></tr><tr><td align="left">2b</td><td align="left">State the aims and research questions including the target audience, intervention, comparator(s), and outcome(s).</td><td align="left"/></tr><tr><td align="left" colspan="4">Methods</td></tr><tr><td align="left" rowspan="2">&#x02003;Model Identifiers</td><td align="left">3a</td><td align="left">State the name and version identifier(s) of the generative AI model(s) and chatbot(s) under evaluation, as well as their date of release or last update.</td><td align="left"/></tr><tr><td align="left">3b</td><td align="left">State whether the generative AI model(s) and chatbot(s) are open-source or closed-source/proprietary.</td><td align="left"/></tr><tr><td align="left" rowspan="3">&#x02003;Model Details</td><td align="left">4a</td><td align="left">State whether the generative AI model was a base model or a novel base model, tuned model, or fine-tuned model.</td><td align="left"/></tr><tr><td align="left">4b</td><td align="left">If a base model is used, cite its development in sufficient detail to identify the model.</td><td align="left"/></tr><tr><td align="left">4c</td><td align="left">If a novel base model, tuned model, or fine-tuned model is used, describe the pre- and/or post-implementation/deployment data and parameters.</td><td align="left"/></tr><tr><td align="left" rowspan="5">&#x02003;Prompt Engineering</td><td align="left">5a</td><td align="left">Describe the evolution of study prompt development.</td><td align="left"/></tr><tr><td align="left">5ai</td><td align="left">Describe the sources of prompts.</td><td align="left"/></tr><tr><td align="left">5aii</td><td align="left">State the number and characteristics of the individual(s) involved in prompt engineering.</td><td align="left"/></tr><tr><td align="left">5aiii</td><td align="left">Provide details of any patient and public involvement during prompt engineering.</td><td align="left"/></tr><tr><td align="left">5b</td><td align="left">Provide study prompts.</td><td align="left"/></tr><tr><td align="left" rowspan="4">&#x02003;Query Strategy</td><td align="left">6a</td><td align="left">State route of access to generative AI model.</td><td align="left"/></tr><tr><td align="left">6b</td><td align="left">State the date(s) and location(s) of queries for the generative AI-driven chatbot(s) including the day, month, and year as well as city and country.</td><td align="left"/></tr><tr><td align="left">6c</td><td align="left">Describe whether prompts were input into separate chat session(s).</td><td align="left"/></tr><tr><td align="left">6d</td><td align="left">Provide all generative AI-driven chatbot output/responses</td><td align="left"/></tr><tr><td align="left" rowspan="5">&#x02003;Performance Evaluation</td><td align="left">7a</td><td align="left">Define the ground truth or reference standard used to define successful generative AI-driven chatbot performance.</td><td align="left"/></tr><tr><td align="left">7b</td><td align="left">Describe the process undertaken for generative AI-driven chatbot performance evaluation.</td><td align="left"/></tr><tr><td align="left">7bi</td><td align="left">State the number and characteristics of team members involved in performance evaluation.</td><td align="left"/></tr><tr><td align="left">7bii</td><td align="left">Provide details of any patients and public involvement during the evaluation process.</td><td align="left"/></tr><tr><td align="left">7biii</td><td align="left">State whether evaluators were blinded to the identity of the generative AI-driven chatbot(s) under assessment.</td><td align="left"/></tr><tr><td align="left">&#x02003;Sample Size</td><td align="left">8</td><td align="left">Report how the sample size was determined.</td><td align="left"/></tr><tr><td align="left" rowspan="2">&#x02003;Data Analysis</td><td align="left">9a</td><td align="left">Describe statistical analysis methods, including any evaluation of reproducibility of generative AI-driven chatbot responses.</td><td align="left"/></tr><tr><td align="left">9ai</td><td align="left">Report the measures used for performance evaluation.</td><td align="left"/></tr><tr><td align="left" colspan="4">Results</td></tr><tr><td align="left"/><td align="left">10a</td><td align="left">Report the performance evaluation undertaken including the alignment between generative AI-driven chatbot output and ground truth or reference standard using quantitative or mixed methods approaches as applicable.</td><td align="left"/></tr><tr><td align="left"/><td align="left">10b</td><td align="left">For responses deviating from the ground truth or reference standard, state the nature of the difference(s).</td><td align="left"/></tr><tr><td align="left"/><td align="left">10c</td><td align="left">Report the evaluation for potentially harmful, biased, or misleading responses.</td><td align="left"/></tr><tr><td align="left" colspan="4">Discussion</td></tr><tr><td align="left"/><td align="left">11a</td><td align="left">Interpret study findings in the context of relevant evidence.</td><td align="left"/></tr><tr><td align="left"/><td align="left">11b</td><td align="left">Describe the strengths and limitations of the study.</td><td align="left"/></tr><tr><td align="left"/><td align="left">11c</td><td align="left">Describe the potential implications for practice, education, policy, regulation, and research.</td><td align="left"/></tr><tr><td align="left" colspan="4">Open Science</td></tr><tr><td align="left">&#x02003;Disclosures</td><td align="left">12a</td><td align="left">Report any relevant conflicts of interest for all authors.</td><td align="left"/></tr><tr><td align="left">&#x02003;Funding</td><td align="left">12b</td><td align="left">Report sources of funding and their role in the conduct and reporting of the study.</td><td align="left"/></tr><tr><td align="left" rowspan="3">&#x02003;Ethics</td><td align="left">12c</td><td align="left">Describe the process undertaken for ethical approval.</td><td align="left"/></tr><tr><td align="left">12ci</td><td align="left">Describe the measures taken to safeguard data privacy of patient health information, as applicable.</td><td align="left"/></tr><tr><td align="left">12cii</td><td align="left">State whether permission/licensing was obtained for the use of original, copyrighted data.</td><td align="left"/></tr><tr><td align="left">&#x02003;Protocol</td><td align="left">12d</td><td align="left">Provide a study protocol.</td><td align="left"/></tr><tr><td align="left">&#x02003;Data availability</td><td align="left">12e</td><td align="left">State where study data, code repository, and model parameters can be accessed.</td><td align="left"/></tr></tbody></table></table-wrap></p><p id="Par19">The Delphi advisory committee and the expert panel both emphasized the importance of several checklist items. Specific examples are highlighted here, but the thorough reporting of all items listed in Table <xref rid="Tab2" ref-type="table">2</xref> is recommended. Delphi and panel members both voiced that authors must adequately identify the generative AI model and chatbot which they evaluated (items 3 and 4). This includes model identifiers, whether it is an open-source or proprietary model, and whether the model was novel or a base model (Table <xref rid="Tab2" ref-type="table">2</xref>). Our expert stakeholders further stressed that authors must report the details involved during prompt engineering as well as the query strategy applied by investigators (item 5 and 6). This includes the process used to develop prompts, the members of the study team involved, and the dates and locations of queries (Table <xref rid="Tab2" ref-type="table">2</xref>). Our panelists also underscored the necessity of explicitly defining a reference standard and describing the performance evaluation process (item 7). Stakeholders emphasized the importance of providing a sample size, which includes the number of independent responses from one or more generative AI-driven chatbot(s). Panelists also identified that the sample size of training data points may also be relevant if authors evaluate a novel or tuned model. Additionally, panelists stressed the importance of reporting the training data used, the ethical approval process undertaken, measures to safeguard the privacy of patient data, the permission or licensing obtained for the use of training data, and whether the training data can be accessed (item 12) (Table <xref rid="Tab3" ref-type="table">3</xref>).
<table-wrap id="Tab3"><label>Table 3</label><caption><p>The CHART Abstract Checklist</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">
<bold>HEADING</bold>
</th><th align="left">
<bold>CHART Checklist #</bold>
</th><th align="left">
<bold>ITEM</bold>
</th><th align="left">
<bold>Page #</bold>
</th></tr></thead><tbody><tr><td align="left" rowspan="2">Background</td><td align="left">2a</td><td align="left">State the scientific background, rationale, and healthcare context for evaluating the generative AI-driven chatbot(s), referencing relevant literature when applicable.</td><td align="left"/></tr><tr><td align="left">2b</td><td align="left">State the aims and research questions including the target audience, intervention, comparator(s), and outcome(s).</td><td align="left"/></tr><tr><td align="left" colspan="4">Methods</td></tr><tr><td align="left" rowspan="2">&#x02003;Model Identifiers</td><td align="left">3a</td><td align="left">State the name and version identifier(s) of the generative AI model(s) and chatbot(s) under evaluation, as well as their date of release or last update.</td><td align="left"/></tr><tr><td align="left">3b</td><td align="left">State whether generative AI model(s) and chatbot(s) are open-source versus closed-source/proprietary.</td><td align="left"/></tr><tr><td align="left">&#x02003;Model Details</td><td align="left">4a</td><td align="left">State whether the generative AI model was a base model or a novel base model, tuned model, or fine-tuned model.</td><td align="left"/></tr><tr><td align="left" rowspan="4">&#x02003;Prompt Engineering</td><td align="left">5a</td><td align="left">Describe the evolution of study prompt development.</td><td align="left"/></tr><tr><td align="left">5ai</td><td align="left">Describe the sources of prompts.</td><td align="left"/></tr><tr><td align="left">5aii</td><td align="left">State the number and characteristics of the individual(s) involved in prompt engineering.</td><td align="left"/></tr><tr><td align="left">5aiii</td><td align="left">Provide details of any patient and public involvement during prompt engineering.</td><td align="left"/></tr><tr><td align="left" rowspan="2">&#x02003;Query Strategy</td><td align="left">6a</td><td align="left">State route of access to generative AI model.</td><td align="left"/></tr><tr><td align="left">6b</td><td align="left">State the date(s) and location(s) of queries for the generative AI-driven chatbot(s) including the day, month, and year as well as city and country.</td><td align="left"/></tr><tr><td align="left" rowspan="2">&#x02003;Performance Evaluation</td><td align="left">7a</td><td align="left">Define the ground truth or reference standard used to define successful generative AI-driven chatbot performance.</td><td align="left"/></tr><tr><td align="left">7b</td><td align="left">Describe the process undertaken for the performance evaluation of the generative AI-driven chatbot(s).</td><td align="left"/></tr><tr><td align="left">&#x02003;Sample Size</td><td align="left">8</td><td align="left">Report how the sample size was determined.</td><td align="left"/></tr><tr><td align="left">&#x02003;Data Analysis</td><td align="left">9a</td><td align="left">Describe statistical analysis methods, including any evaluation of reproducibility of generative AI-driven chatbot responses.</td><td align="left"/></tr><tr><td align="left" colspan="4">Results</td></tr><tr><td align="left"/><td align="left">10a</td><td align="left">Report the alignment between generative AI-driven chatbot output and ground truth or reference standard using quantitative or mixed methods approaches as applicable.</td><td align="left"/></tr></tbody></table></table-wrap></p></sec><sec id="Sec8"><title>Discussion</title><p id="Par20"> CHART was developed in accordance with the highest methodological standards through a comprehensive systematic review of CHA studies, a modified asynchronous Delphi process conducted by an international, multidisciplinary advisory committee, and three synchronous international, multidisciplinary expert panel consensus meetings [<xref ref-type="bibr" rid="CR7">7</xref>]. Detailed rationale for each subitem are described in our Explanation and Elaboration article [<xref ref-type="bibr" rid="CR14">14</xref>]. The CHART checklist outlines essential items for the reporting of CHA studies which typically evaluate the performance of generative AI-driven chatbots when summarizing clinical evidence or providing health advice. At the time of writing, substantial advancements are being made in other forms of generative AI such as large multimodal models (LMMs), to which our reporting checklist&#x02014;developed in the context of studies evaluating LLM performance&#x02014;may not fully apply [<xref ref-type="bibr" rid="CR15">15</xref>]. Thus, due to the rapidly evolving nature of these studies, a dynamic process must be in place for the monitoring and updating of this reporting guideline [<xref ref-type="bibr" rid="CR16">16</xref>].</p><sec id="Sec9"><title>Applicability and scope</title><p id="Par21">The CHART checklist applies to CHA studies where generative AI-driven chatbots are queried and their responses are reported and evaluated. The CHART checklist does not apply to CHA studies applying randomization techniques (randomized controlled trials), nor studies that follow patients over time (prospective cohort studies). Future CHART extensions of relevant checklists for various study designs are planned, but in the interim authors are encouraged to apply both the CHART checklist and relevant reporting guidelines according to the appropriate study design such as CONSORT or STROBE [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>]. Authors using applications in the field of artificial intelligence more broadly (but not generative AI) are encouraged to use more generic reporting guidelines [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. Authors using generative AI models for medical writing are encouraged to apply the CANGARU reporting guidelines, which are in development [<xref ref-type="bibr" rid="CR21">21</xref>]. CHART applies to the current landscape of CHA studies and will evolve as a living reporting guideline.</p></sec><sec id="Sec10"><title>How to use CHART</title><p id="Par22">We suggest that authors use the CHART checklist early in the writing of CHA studies to ensure all items in the checklist have been reported somewhere in their manuscript. Many of the recommendations in the CHART checklist have a natural order and sequence in a CHA study, but some may not. We do not prescribe a specific format or dictate where each individual reporting recommendation should appear in a CHA study, because this order might also depend on journal formatting policies. A downloadable and editable checklist can be found in the supplementary material. Authors are recommended to complete the checklist indicating the page number where each subitem has been reported. The completed checklist can then be submitted alongside the CHA study manuscript. A detailed Explanation and Elaboration paper accompanies the CHART checklist and explains why the reporting of each item is recommended [<xref ref-type="bibr" rid="CR14">14</xref>].</p></sec><sec id="Sec11"><title>Copyright protections and fair use doctrine</title><p id="Par23">The accuracy of LLMs is significantly influenced by the nature of the data on which they were trained [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. This principle is the first of four according to the fair use doctrine, which are addressed throughout the CHART checklist as they relate to CHA studies. The first principle refers to the purpose and character of use of the model [<xref ref-type="bibr" rid="CR10">10</xref>]. The second principle is the nature of the original training data [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. While many LLMs will be trained on non-medical data, it is essential that factual, evidence-based information must be prioritized in the healthcare setting [<xref ref-type="bibr" rid="CR10">10</xref>]. The third principle pertains to the amount and substantiality of original material used to train the generative AI model [<xref ref-type="bibr" rid="CR10">10</xref>], and clarity regarding the origin of training data and permission or license to use content or data protected by copyright is recommended. Finally, the fourth principle relates to the impact on original work, where generative AI models may be trained with copyrighted data [<xref ref-type="bibr" rid="CR10">10</xref>]. We address these principles in the CHART checklist by encouraging authors to state the purpose of the study, and whether they are evaluating a pre-existing base model rather than one that is a novel base model, a tuned model, or a fine-tuned model (items 3 and 4). The CHART checklist promotes open science practices and calls for authors to share their code and training datasets to optimize transparency and mitigate uncertainty over data provenance (item 12e). The CHART checklist further uses an evidence-based approach by encouraging authors to state the source of their prompts, their definition of successful model/bot performance, and the process behind performance evaluation (item 5, item 7). The CHART checklist recommends that authors state whether permission or license was obtained by investigators for use of the original work (item 12cii). Readers may also identify the presence of copyrighted data as authors share their coding and training data (item 12e).</p></sec><sec id="Sec12"><title>Bias and patient safety</title><p id="Par24">In the setting of model development, the output of generative AI models such as LLMs are further impacted by the presence of bias in their training datasets [<xref ref-type="bibr" rid="CR10">10</xref>]. This introduces the risk of LLMs producing misleading or harmful information when applied for the purposes of patient care. These biases may pertain to many factors including, but not limited to race or ethnicity, sex or gender, language, and culture [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. This risk further highlights the importance of the Open Science checklist item (item 12) in CHART because the risk of bias from data used to develop LLM-driven chatbots may be identified and/or mitigated by open coding and training data sharing [<xref ref-type="bibr" rid="CR25">25</xref>]. Furthermore, data used to train generative AI models may pose a threat to data security and patient privacy. The use of identifiable patient data during model training is of particular concern, as sensitive information may be inadvertently disclosed in the absence of appropriate data security measures [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. The risk for data breaches must be met accordingly with robust cybersecurity measures [<xref ref-type="bibr" rid="CR10">10</xref>]. This concept underscores the importance of the CHART checklist item related to steps taken to ensure safeguarding of patient health information (item 12ci). The push for clinically integrating generative AI models necessitates human oversight of the ethical and safe inclusion of patients and their health information to provide guidance for the safe conduct of CHA studies [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR28">28</xref>]. Although we recognize the importance of making advancements by including patients in CHA studies to develop more patient-centered studies (item 5biii, item 7bii), we encourage authors to report whether ethics approval was obtained in these instances for the responsible conduct of their study (item 12c).</p></sec><sec id="Sec13"><title>Monitoring and updates</title><p id="Par25">This reporting guideline will follow and adapt the traditional methodology for a living clinical practice guideline [<xref ref-type="bibr" rid="CR16">16</xref>]. The update interval for this reporting guideline will apply to individual checklist items, rather than the entire guideline [<xref ref-type="bibr" rid="CR16">16</xref>]. Core members of the steering group will perform a systematic search of the literature to continuously survey the literature per living guideline best practices [<xref ref-type="bibr" rid="CR16">16</xref>] and will meet to discuss any relevant developments in the generative AI field every 6 months for the first 2 years (until 2026). If important changes occur sooner, the group will meet ad hoc as needed. The timing for monitoring and updating the guideline will be reviewed and revised at the time of the next reporting guideline update or by the end of 2026, whichever occurs sooner.</p><p id="Par26">Furthermore, a living expert panel consisting of 14 expert panel members was selected following the third expert panel consensus meeting in accordance with living guideline best practices [<xref ref-type="bibr" rid="CR16">16</xref>], and comprised panel members committed to making themselves available to meet virtually at very short notice [<xref ref-type="bibr" rid="CR16">16</xref>]. Living expert panel members represent backgrounds stemming from medicine, epidemiology, data science, health research methodology, reporting guideline methodology, and statistics. If no changes to the reporting guideline are warranted within a given year, the living expert panel will be updated with the activities of the core steering group and will be alerted to any relevant literature or topics within generative AI to monitor and be aware of. This update will occur at a minimum of once per year at a meeting between the core members of the steering group and the living expert panel. Finally, living peer reviewers will be selected following the peer review process for the CHART statement and Elaboration and Explanation articles [<xref ref-type="bibr" rid="CR16">16</xref>]. They will similarly be provided with an annual update, but will only be contacted if checklist items must be updated. If new candidate checklist items or revisions to existing items are identified by the core members of the steering group, the living expert panel will be convened at its earliest convenience to review the relevant literature. In alignment with living guideline best practices [<xref ref-type="bibr" rid="CR16">16</xref>], the minimum threshold will be set at 90% agreement among living expert panel members for changing checklist items to mitigate the risk of false positives inherent to frequent updates, while avoiding an excessively high threshold [<xref ref-type="bibr" rid="CR16">16</xref>]. If applicable, the updated manuscript will be co-published in relevant journals with interest.</p></sec><sec id="Sec14"><title>Target users and implications for stakeholders</title><p id="Par27">CHART applies to individuals performing and reviewing CHA studies such as study investigators, peer reviewers, and journal editors for academic purposes, as well as the wider readership of CHA studies including clinicians, statisticians, generative AI researchers, regulatory experts, ethicists, research methodologists, policy makers, hospital managers, funders, patients, and the wider public. To promote the transparent reporting of CHA studies, we call for clinical journals to adopt CHART: a comprehensive reporting standard developed with high methodological rigor. The main barrier that we anticipate to CHART uptake is the failure to reach the appropriate audience. Therefore, this reporting guideline will be listed on the EQUATOR Network website, and we will disseminate the publication of this reporting guideline widely. CHART will also be presented at peer-reviewed meetings across various medical specialties to optimize the dissemination and reach of the checklist and accompanying diagram. Finally, we will develop a website to house fillable versions of the abstract checklist, the full checklist, and the methodological diagram, which can be found in supplementary Appendices 2&#x02013;4 of this publication to facilitate the application of CHART by CHA researchers.</p><p id="Par28">Following the publication of previous reporting guidelines, it has been shown that the reporting quality of applicable studies improve [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>]. As investigators and journals apply CHART and the completeness of reporting of CHA studies improve, higher quality studies may be produced. Researchers, ethicists, clinicians, and regulators in the clinical generative AI community must then turn toward the validation of generative AI-driven chatbots for the purposes of providing health advice [<xref ref-type="bibr" rid="CR10">10</xref>]. This may include the prioritization of standardized quality validation metrics, clarifying the role of human involvement in validation studies, validation methodology [<xref ref-type="bibr" rid="CR31">31</xref>], and the reporting of validation results using the CHART tool. Regulators must further look toward data sensitivity and privacy, ensuring that data security measures are put in place by generative AI developers according to risk category [<xref ref-type="bibr" rid="CR10">10</xref>]. Funders must invest in the development of high-quality benchmarking and validation studies, as well as highly rigorous CHA studies in the context of the healthcare setting of interest. Funders may also encourage applicants to include a research plan in alignment with the CHART checklist. With studies exhibiting greater transparency and improved methodological rigor, clinicians, patients, and the public will develop progressively increased trust in the clinical integration of generative AI-driven chatbots.</p><p id="Par29">Finally, quality appraisal tools do not exist for CHA studies and remains a future area of study. CHART is a reporting guideline rather than a critical appraisal tool. Still, we hope that attention to CHART&#x02019;s core checklist items will indirectly improve the methodologic rigor of studies in this field [<xref ref-type="bibr" rid="CR32">32</xref>]. As high-quality evidence builds, the path forward for integrating generative AI into the clinical practice environment will become clearer for both hospital managers and policy makers.</p></sec></sec><sec id="Sec15"><title>Conclusion</title><p id="Par30">The transparent reporting of CHA studies is crucial for their interpretation as we move toward the clinical integration of AI technologies. The CHART reporting guideline consists of a 12-item checklist and corresponding methodological diagram to support key stakeholders including clinicians, researchers, editors, peer reviewers, and readers in reporting, understanding, and interpreting the findings of CHA studies. </p></sec><sec id="Sec16" sec-type="supplementary-material"><title>Supplementary Information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="12916_2025_4274_MOESM1_ESM.docx"><caption><p>Additional file 1: Appendix 1 Candidate checklist items.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="12916_2025_4274_MOESM2_ESM.docx"><caption><p>Additional file 2: Appendix 2 Fillable CHART checklist.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="12916_2025_4274_MOESM3_ESM.docx"><caption><p>Additional file 3: Appendix 3 Fillable CHART abstract checklist.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM4"><media xlink:href="12916_2025_4274_MOESM4_ESM.docx"><caption><p>Additional file 4: Appendix 4 Fillable methodological diagram.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM5"><media xlink:href="12916_2025_4274_MOESM5_ESM.docx"><caption><p>Additional file 5: Appendix 5 Panel members.</p></caption></media></supplementary-material></p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The authors would like to thank the First Cut competition organizers and the Postgraduate Medical Education Committee at McMaster University for financially supporting the development of this project. The authors would also like to thank members of the Advisory Committee for their invaluable time and effort devoted to the development of the Chatbot Assessment Reporting Tool.</p></ack><notes notes-type="author-contribution"><title>Authors&#x02019; contributions</title><p>BH, DC, AWC, CL, and GG contributed to the conception and design of the work. All authors contributed to data analysis, interpretation, manuscript drafting, revising, and approve of the final version to be published. BH acted as guarantor and is responsible for the overall content (as guarantor), and all authors are accountable for the accuracy of the checklist and methodological diagram.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>The Chatbot Assessment Reporting Tool (CHART) was funded by the <italic>First Cut</italic> competition and the Postgraduate Medical Education Committee at McMaster University. Neither funding sources were involved in the design, conduct, or reporting of this reporting guideline.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>No datasets were generated or analysed during the current study.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics approval and consent to participate</title><p id="Par31">Ethics approval was submitted to and waived by the Hamilton Integrated Research Ethics Board (HiREB #17025).</p></notes><notes id="FPar2"><title>Consent for publication</title><p id="Par32">Not applicable.</p></notes><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par33">All authors have completed the ICMJE uniform disclosure form at <ext-link ext-link-type="uri" xlink:href="https://www.icmje.org/disclosure-of-interest/">www.icmje.org/disclosure-of-interest/</ext-link> and declare: GSC is a National Institute for Health and Care Research (NIHR) Senior Investigator. The views expressed in this article are those of the author(s) and not necessarily those of the NIHR, or the Department of Health and Social Care; AJT has received funding from HealthSense to investigate evidence-based medicine applications of large language models. PM is the co-founder of BrainX LLC; AS has received research funding from the Australian government and is co-founder of BantingMed Pty Ltd; DS is the Acting Deputy Editor for the Lancet Digital Health; MM has received research funding from The Hospital Research Founding Group; TF sits on the executive committee of MDEpiNet; HF is a Senior Executive Editor for The Lancet; CL is the Editor in Chief of Annals of Internal Medicine; AF is Executive Managing Editor and Vice President, Editorial Operations, JAMA and The JAMA Network; TF and EL are journal editors for the BMJ; RA is the Editor in Chief of International Journal of Surgery; GS is an Executive Editor of Artificial Intelligence in Medicine; SL is a paid consultant for Astellas; DP has received research funding from the Italian Ministry of University and Research; MO is a paid consultant for Theator; TA, POV, GG are board member of the MAGIC Evidence Ecosystem Foundation (<ext-link ext-link-type="uri" xlink:href="https://www.magicproject.org">www.magicproject.org</ext-link>), a non-for profit organization, which conducts research and evidence appraisal and guideline methodology and implementation, and which provides a authoring and publication software (MAGICapp) for evidence summaries, guidelines and decision aids.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Kolbinger</surname><given-names>FR</given-names></name><name><surname>Veldhuizen</surname><given-names>GP</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Truhn</surname><given-names>D</given-names></name><name><surname>Kather</surname><given-names>JN</given-names></name></person-group><article-title>Reporting guidelines in medical artificial intelligence: a systematic review and meta-analysis</article-title><source>Commun Med</source><year>2024</year><volume>4</volume><fpage>1</fpage><pub-id pub-id-type="pmid">38172187</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Kolbinger FR, Veldhuizen GP, Zhu J, Truhn D, Kather JN. Reporting guidelines in medical artificial intelligence: a systematic review and meta-analysis. Commun Med. 2024;4:1.<pub-id pub-id-type="pmid">38172187</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>R</given-names></name><name><surname>Acosta</surname><given-names>JN</given-names></name><name><surname>Shakeri</surname><given-names>Z</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name><name><surname>Topol</surname><given-names>EJ</given-names></name><name><surname>Rajpurkar</surname><given-names>P</given-names></name></person-group><article-title>Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review</article-title><source>Lancet Digit Health.</source><year>2024</year><volume>6</volume><fpage>e367</fpage><lpage>e373</lpage><pub-id pub-id-type="pmid">38670745</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Han R, Acosta JN, Shakeri Z, Ioannidis JPA, Topol EJ, Rajpurkar P. Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review. Lancet Digit Health. 2024;6:e367&#x02013;73.<pub-id pub-id-type="pmid">38670745</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>B</given-names></name><name><surname>Cacciamani</surname><given-names>GE</given-names></name><name><surname>Collins</surname><given-names>GS</given-names></name><name><surname>McKechnie</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>Y</given-names></name><name><surname>Guyatt</surname><given-names>G</given-names></name></person-group><article-title>Reporting standards for the use of large language model-linked chatbots for health advice</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><fpage>2988</fpage><pub-id pub-id-type="pmid">37957381</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Huo B, Cacciamani GE, Collins GS, McKechnie T, Lee Y, Guyatt G. Reporting standards for the use of large language model-linked chatbots for health advice. Nat Med. 2023;29:2988.<pub-id pub-id-type="pmid">37957381</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>B</given-names></name><name><surname>McKechnie</surname><given-names>T</given-names></name><name><surname>Ortenzi</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>Y</given-names></name><name><surname>Antoniou</surname><given-names>S</given-names></name><name><surname>Mayol</surname><given-names>J</given-names></name><etal/></person-group><article-title>Dr. GPT will see you now: the ability of large language model-linked chatbots to provide colorectal cancer screening recommendations</article-title><source>Health Technol.</source><year>2024</year><volume>14</volume><fpage>463</fpage><lpage>9</lpage></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Huo B, McKechnie T, Ortenzi M, Lee Y, Antoniou S, Mayol J, et al. Dr. GPT will see you now: the ability of large language model-linked chatbots to provide colorectal cancer screening recommendations. Health Technol. 2024;14:463&#x02013;9.</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>B</given-names></name><name><surname>Marfo</surname><given-names>N</given-names></name><name><surname>Sylla</surname><given-names>P</given-names></name><name><surname>Calabrese</surname><given-names>E</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Slater</surname><given-names>BJ</given-names></name><etal/></person-group><article-title>Clinical artificial intelligence: teaching a large language model to generate recommendations that align with guidelines for the surgical management of GERD</article-title><source>Surg Endosc</source><year>2024</year><volume>38</volume><fpage>5668</fpage><lpage>5677</lpage><pub-id pub-id-type="pmid">39134725</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Huo B, Marfo N, Sylla P, Calabrese E, Kumar S, Slater BJ, et al. Clinical artificial intelligence: teaching a large language model to generate recommendations that align with guidelines for the surgical management of GERD. Surg Endosc. 2024;38:5668&#x02013;77.<pub-id pub-id-type="pmid">39134725</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>B</given-names></name><name><surname>Boyle</surname><given-names>A</given-names></name><name><surname>Marfo</surname><given-names>N</given-names></name><name><surname>Tangamornsuksan</surname><given-names>W</given-names></name><name><surname>Steen</surname><given-names>JP</given-names></name><name><surname>McKechnie</surname><given-names>T</given-names></name><etal/></person-group><article-title>Large language models for chatbot health advice studies: a systematic review</article-title><source>JAMA Netw Open</source><year>2025</year><volume>8</volume><fpage>e2457879</fpage><pub-id pub-id-type="pmid">39903463</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Huo B, Boyle A, Marfo N, Tangamornsuksan W, Steen JP, McKechnie T, et al. Large language models for chatbot health advice studies: a systematic review. JAMA Netw Open. 2025;8: e2457879.<pub-id pub-id-type="pmid">39903463</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">The CHART Collaborative. Protocol for the development of the Chatbot Assessment Reporting Tool (CHART) for clinical advice. BMJ Open. 2024;14:e081155.</mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Schulz</surname><given-names>KF</given-names></name><name><surname>Simera</surname><given-names>I</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><article-title>Guidance for developers of health research reporting guidelines</article-title><source>PLoS Med</source><year>2010</year><volume>17</volume><fpage>e1000217</fpage></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Moher D, Schulz KF, Simera I, Altman DG. Guidance for developers of health research reporting guidelines. PLoS Med. 2010;17: e1000217.</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>GS</given-names></name><name><surname>Moons</surname><given-names>KGM</given-names></name><name><surname>Dhiman</surname><given-names>P</given-names></name><name><surname>Riley</surname><given-names>RD</given-names></name><name><surname>Beam</surname><given-names>AL</given-names></name><name><surname>Van Calster</surname><given-names>B</given-names></name><etal/></person-group><article-title>TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods</article-title><source>BMJ</source><year>2024</year><volume>384</volume><fpage>q902</fpage></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Collins GS, Moons KGM, Dhiman P, Riley RD, Beam AL, Van Calster B, et al. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods. BMJ. 2024;384: q902.</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Ong</surname><given-names>JCL</given-names></name><name><surname>Chang</surname><given-names>SYH</given-names></name><name><surname>William</surname><given-names>W</given-names></name><name><surname>Butte</surname><given-names>AJ</given-names></name><name><surname>Shah</surname><given-names>NH</given-names></name><name><surname>Chew</surname><given-names>LST</given-names></name><etal/></person-group><article-title>Ethical and regulatory challenges of large language models in medicine</article-title><source>The Lancet Digital Health. Elsevier Ltd</source><year>2024</year><volume>6</volume><fpage>e428</fpage><lpage>e432</lpage></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Ong JCL, Chang SYH, William W, Butte AJ, Shah NH, Chew LST, et al. Ethical and regulatory challenges of large language models in medicine. The Lancet Digital Health Elsevier Ltd. 2024;6:e428&#x02013;32.</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Simera</surname><given-names>I</given-names></name><name><surname>Hoey</surname><given-names>J</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Schulz</surname><given-names>K</given-names></name></person-group><article-title>EQUATOR: reporting guidelines for health research</article-title><source>Open Med</source><year>2008</year><volume>371</volume><fpage>1149</fpage><lpage>1150</lpage></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Altman DG, Simera I, Hoey J, Moher D, Schulz K. EQUATOR: reporting guidelines for health research. Open Med. 2008;371:1149&#x02013;50.</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Munn</surname><given-names>Z</given-names></name><name><surname>Peters</surname><given-names>MDJ</given-names></name><name><surname>Stern</surname><given-names>C</given-names></name><name><surname>Tufanaru</surname><given-names>C</given-names></name><name><surname>McArthur</surname><given-names>A</given-names></name><name><surname>Aromataris</surname><given-names>E</given-names></name></person-group><article-title>Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach</article-title><source>BMC Med Res Methodol</source><year>2018</year><volume>18</volume><fpage>143</fpage><pub-id pub-id-type="pmid">30453902</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Munn Z, Peters MDJ, Stern C, Tufanaru C, McArthur A, Aromataris E. Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach. BMC Med Res Methodol. 2018;18:143.<pub-id pub-id-type="pmid">30453902</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Rivera</surname><given-names>SC</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Calvert</surname><given-names>MJ</given-names></name><name><surname>Denniston</surname><given-names>AK</given-names></name></person-group><article-title>Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI Extension</article-title><source>BMJ</source><year>2020</year><volume>370</volume><fpage>m3164</fpage><pub-id pub-id-type="pmid">32909959</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Liu X, Rivera SC, Moher D, Calvert MJ, Denniston AK. Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI Extension. BMJ. 2020;370: m3164.<pub-id pub-id-type="pmid">32909959</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><collab>The CHART Collaborative</collab></person-group><article-title>Reporting guidelines for chatbot health advice studies: explanation and elaboration for the Chatbot Assessment Reporting Tool (CHART)</article-title><source>BMJ</source><year>2025</year><volume>390</volume><fpage>e083305</fpage></element-citation><mixed-citation id="mc-CR14" publication-type="journal">The CHART Collaborative. Reporting guidelines for chatbot health advice studies: explanation and elaboration for the Chatbot Assessment Reporting Tool (CHART). BMJ. 2025;390: e083305.</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Yin S, Fu C, Zhao S, Li K, Sun X, Xu T, et al. A survey on multimodal large language models. 2023.&#x000a0;<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2306.13549">http://arxiv.org/abs/2306.13549</ext-link>.&#x000a0;Accessed 24 Jun 2025.</mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Akl</surname><given-names>EA</given-names></name><name><surname>Meerpohl</surname><given-names>JJ</given-names></name><name><surname>Elliott</surname><given-names>J</given-names></name><name><surname>Kahale</surname><given-names>LA</given-names></name><name><surname>Sch&#x000fc;nemann</surname><given-names>HJ</given-names></name><name><surname>Agoritsas</surname><given-names>T</given-names></name><etal/></person-group><article-title>Living systematic reviews: 4. Living guideline recommendations. Vol. 91</article-title><source>J Clin Epidemiol.</source><year>2017</year><volume>91</volume><fpage>47</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">28911999</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Akl EA, Meerpohl JJ, Elliott J, Kahale LA, Sch&#x000fc;nemann HJ, Agoritsas T, et al. Living systematic reviews: 4. Living guideline recommendations. Vol. 91. J Clin Epidemiol. 2017;91:47&#x02013;53.<pub-id pub-id-type="pmid">28911999</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Begg</surname><given-names>C</given-names></name><name><surname>Cho</surname><given-names>M</given-names></name><name><surname>Eastwood</surname><given-names>S</given-names></name><name><surname>Horton</surname><given-names>R</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Olkin</surname><given-names>I</given-names></name><etal/></person-group><article-title>Improving the quality of reporting of randomized controlled trials</article-title><source>The CONSORT statement. JAMA.</source><year>1996</year><volume>276</volume><fpage>637</fpage><lpage>639</lpage></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Begg C, Cho M, Eastwood S, Horton R, Moher D, Olkin I, et al. Improving the quality of reporting of randomized controlled trials. The CONSORT statement JAMA. 1996;276:637&#x02013;9.</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>von Elm</surname><given-names>E</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Egger</surname><given-names>M</given-names></name><name><surname>Pocock</surname><given-names>SJ</given-names></name><name><surname>G&#x000f8;tzsche</surname><given-names>PC</given-names></name><name><surname>Vandenbroucke</surname><given-names>JP</given-names></name></person-group><article-title>Strengthening the reporting of observational studies in epidemiology (STROBE) statement: guidelines for reporting observational studies</article-title><source>BMJ</source><year>2007</year><volume>335</volume><fpage>806</fpage><lpage>808</lpage><pub-id pub-id-type="pmid">17947786</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">von Elm E, Altman DG, Egger M, Pocock SJ, G&#x000f8;tzsche PC, Vandenbroucke JP. Strengthening the reporting of observational studies in epidemiology (STROBE) statement: guidelines for reporting observational studies. BMJ. 2007;335:806&#x02013;8.<pub-id pub-id-type="pmid">17947786</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Rivera</surname><given-names>SC</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Chan</surname><given-names>AW</given-names></name><name><surname>Denniston</surname><given-names>AK</given-names></name><name><surname>Calvert</surname><given-names>MJ</given-names></name></person-group><article-title>Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI Extension</article-title><source>The BMJ.</source><year>2020</year><volume>370</volume><fpage>m3210</fpage><pub-id pub-id-type="pmid">32907797</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Rivera SC, Liu X, Chan AW, Denniston AK, Calvert MJ. Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI Extension. The BMJ. 2020;370: m3210.<pub-id pub-id-type="pmid">32907797</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Vasey</surname><given-names>B</given-names></name><name><surname>Nagendran</surname><given-names>M</given-names></name><name><surname>Campbell</surname><given-names>B</given-names></name><name><surname>Clifton</surname><given-names>DA</given-names></name><name><surname>Collins</surname><given-names>GS</given-names></name><name><surname>Denaxas</surname><given-names>S</given-names></name><etal/></person-group><article-title>Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI</article-title><source>Nat Med</source><year>2022</year><volume>28</volume><fpage>924</fpage><lpage>933</lpage><pub-id pub-id-type="pmid">35585198</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Vasey B, Nagendran M, Campbell B, Clifton DA, Collins GS, Denaxas S, et al. Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI. Nat Med. 2022;28:924&#x02013;33.<pub-id pub-id-type="pmid">35585198</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Cacciamani</surname><given-names>G</given-names></name><name><surname>Gill</surname><given-names>I</given-names></name><name><surname>Collins</surname><given-names>G</given-names></name></person-group><article-title>ChatGPT: standard reporting guidelines for responsible use</article-title><source>Nat</source><year>2023</year><volume>618</volume><fpage>1</fpage><lpage>1</lpage></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Cacciamani G, Gill I, Collins G. ChatGPT: standard reporting guidelines for responsible use. Nat. 2023;618:1&#x02013;1.</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Xie SM, Pham H, Dong X, Du N, Liu H, Lu Y, et al. DoReMi: optimizing data mixtures speeds up language model pretraining. 2023.&#x000a0;<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2305.10429">https://arxiv.org/abs/2305.10429</ext-link>. Accessed 24 June 2025.</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>FYC</given-names></name><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name><name><surname>Cheng</surname><given-names>H</given-names></name><name><surname>Tan</surname><given-names>TF</given-names></name><name><surname>Gutierrez</surname><given-names>L</given-names></name><name><surname>Lan</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Artificial intelligence education: an evidence-based medicine approach for consumers, translators, and developers</article-title><source>Cell Rep Med.</source><year>2023</year><volume>4</volume><fpage>101230</fpage><pub-id pub-id-type="pmid">37852174</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Ng FYC, Thirunavukarasu AJ, Cheng H, Tan TF, Gutierrez L, Lan Y, et al. Artificial intelligence education: an evidence-based medicine approach for consumers, translators, and developers. Cell Rep Med. 2023;4: 101230.<pub-id pub-id-type="pmid">37852174</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Moon</surname><given-names>JT</given-names></name><name><surname>Purkayastha</surname><given-names>S</given-names></name><name><surname>Celi</surname><given-names>LA</given-names></name><name><surname>Trivedi</surname><given-names>H</given-names></name><name><surname>Gichoya</surname><given-names>JW</given-names></name></person-group><article-title>Ethics of large language models in medicine and medical research</article-title><source>Lancet Dig Health.</source><year>2023</year><volume>5</volume><fpage>e333</fpage><lpage>e335</lpage></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Li H, Moon JT, Purkayastha S, Celi LA, Trivedi H, Gichoya JW. Ethics of large language models in medicine and medical research. Lancet Dig Health. 2023;5:e333&#x02013;5.</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Health</surname><given-names>TLD</given-names></name></person-group><article-title>Large language models: a new chapter in digital health</article-title><source>Lancet Dig Health.</source><year>2024</year><volume>6</volume><fpage>e1</fpage></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Health TLD. Large language models: a new chapter in digital health. Lancet Dig Health. 2024;6: e1.</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name><name><surname>Ting</surname><given-names>DSJ</given-names></name><name><surname>Elangovan</surname><given-names>K</given-names></name><name><surname>Gutierrez</surname><given-names>L</given-names></name><name><surname>Tan</surname><given-names>TF</given-names></name><name><surname>Ting</surname><given-names>DSW</given-names></name></person-group><article-title>Large language models in medicine</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><fpage>1930</fpage><lpage>1940</lpage><pub-id pub-id-type="pmid">37460753</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med. 2023;29:1930&#x02013;40.<pub-id pub-id-type="pmid">37460753</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Haltaufderheide</surname><given-names>J</given-names></name><name><surname>Ranisch</surname><given-names>R</given-names></name></person-group><article-title>The ethics of ChatGPT in medicine and healthcare: a systematic review on large language models (LLMs)</article-title><source>npj Digit Med.</source><year>2024</year><volume>7</volume><fpage>183</fpage><pub-id pub-id-type="pmid">38977771</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Haltaufderheide J, Ranisch R. The ethics of ChatGPT in medicine and healthcare: a systematic review on large language models (LLMs). npj Digit Med. 2024;7:183.<pub-id pub-id-type="pmid">38977771</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name></person-group><article-title>Large language models will not replace healthcare professionals: curbing popular fears and hype</article-title><source>J R Soc Med</source><year>2023</year><volume>116</volume><fpage>181</fpage><lpage>182</lpage><pub-id pub-id-type="pmid">37199678</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Thirunavukarasu AJ. Large language models will not replace healthcare professionals: curbing popular fears and hype. J R Soc Med. 2023;116:181&#x02013;2.<pub-id pub-id-type="pmid">37199678</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Kane</surname><given-names>RL</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Garrard</surname><given-names>J</given-names></name></person-group><article-title>Reporting in randomized clinical trials improved after adoption of the CONSORT statement</article-title><source>J Clin Epidemiol</source><year>2007</year><volume>60</volume><fpage>241</fpage><lpage>249</lpage><pub-id pub-id-type="pmid">17292017</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Kane RL, Wang J, Garrard J. Reporting in randomized clinical trials improved after adoption of the CONSORT statement. J Clin Epidemiol. 2007;60:241&#x02013;9.<pub-id pub-id-type="pmid">17292017</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>L</given-names></name><name><surname>Shamseer</surname><given-names>L</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Schulz</surname><given-names>KF</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name></person-group><article-title>Does use of the CONSORT statement impact the completeness of reporting of randomised controlled trials published in medical journals?</article-title><source>A Cochrane review. Syst Rev.</source><year>2012</year><volume>1</volume><fpage>60</fpage><pub-id pub-id-type="pmid">23194585</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Turner L, Shamseer L, Altman DG, Schulz KF, Moher D. Does use of the CONSORT statement impact the completeness of reporting of randomised controlled trials published in medical journals? A Cochrane review Syst Rev. 2012;1:60.<pub-id pub-id-type="pmid">23194585</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>de Hond</surname><given-names>A</given-names></name><name><surname>Leeuwenberg</surname><given-names>T</given-names></name><name><surname>Bartels</surname><given-names>R</given-names></name><name><surname>van Buchem</surname><given-names>M</given-names></name><name><surname>Kant</surname><given-names>I</given-names></name><name><surname>GM Moons</surname><given-names>K</given-names></name><etal/></person-group><article-title>From text to treatment: the crucial role of validation for generative large language models in health care</article-title><source>Lancet Digital Health.</source><year>2024</year><volume>6</volume><fpage>e441</fpage><lpage>3</lpage><pub-id pub-id-type="pmid">38906607</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">de Hond A, Leeuwenberg T, Bartels R, van Buchem M, Kant I, GM Moons K, et al. From text to treatment: the crucial role of validation for generative large language models in health care. Lancet Digital Health. 2024;6:e441-3.<pub-id pub-id-type="pmid">38906607</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Logullo</surname><given-names>P</given-names></name><name><surname>Maccarthy</surname><given-names>A</given-names></name><name><surname>Kirtley</surname><given-names>S</given-names></name><name><surname>Collins</surname><given-names>GS</given-names></name></person-group><article-title>Reporting guideline checklists are not quality evaluation forms: they are guidance for writing</article-title><source>Health Sci Rep.</source><year>2020</year><volume>3</volume><fpage>e165</fpage><pub-id pub-id-type="pmid">32373717</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">Logullo P, Maccarthy A, Kirtley S, Collins GS. Reporting guideline checklists are not quality evaluation forms: they are guidance for writing. Health Sci Rep. 2020;3: e165.<pub-id pub-id-type="pmid">32373717</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>